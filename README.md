# Atlas Analyst Agent ğŸ¤–ğŸ“Š

A powerful data analyst AI agent that can analyze CSV, Excel, PDF, and text files through an intuitive chat interface. Built with Next.js, FastAPI, and OpenAI's Responses API. Goal of this is to have a data analyst AI agent that allows uers to upload their data, or have the agent look online and find data per user request at which point it will download and analyze over. 

## âœ¨ Features

- **ğŸ“ File Upload Support**: Drag & drop CSV, Excel, PDF, and text files for analysis
- **ğŸ”„ Real-time Streaming**: Powered by OpenAI's Responses API for fast, responsive interactions
- **ğŸ“Š Data Analysis**: Analyze datasets, generate insights, and create visualizations
- **ğŸŒ Multi-platform Deployment**: Optimized for both Vercel and Railway hosting
- **ğŸ¨ Modern UI**: Beautiful, responsive interface with dark mode support

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ and npm/pnpm
- Python 3.11+ and pip
- OpenAI API key
- Vercel Blob storage (for file uploads)

### 1. Clone and Setup

```bash
git clone https://github.com/yourusername/data_analyst.git
cd data_analyst
pnpm install
```

### 2. Environment Variables

Create a `.env` file:

```bash
# OpenAI API Key (required)
OPENAI_API_KEY=your_openai_api_key_here

# Vercel Blob Storage (for file uploads)
BLOB_READ_WRITE_TOKEN=vercel_blob_rw_your_token_here

# Railway Backend URL (set automatically in production)
RAILWAY_BACKEND_URL=https://your-backend-service.up.railway.app
```

### 3. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### 4. Run Development Servers

```bash
# Terminal 1: Next.js frontend
pnpm run dev

# Terminal 2: FastAPI backend
pnpm run fastapi-dev

# Or run both together:
pnpm run dev
```

## ğŸ“ File Upload Support

Users can upload and analyze:
- **CSV files** (`.csv`) - 10MB max
- **Excel spreadsheets** (`.xlsx`, `.xls`) - 10MB max
- **PDF documents** (`.pdf`) - 50MB max
- **Text files** (`.txt`) - 10MB max

### How It Works

1. **Drag & Drop**: Drop files anywhere on the page or click the ğŸ“ icon
2. **Upload**: Files are stored in Vercel Blob storage
3. **Analysis**: Backend processes files and sends to AI for analysis
4. **Results**: AI provides insights, summaries, and visualizations

## ğŸš¢ Deployment

### Railway (Recommended for ML/Data Science)

Railway offers **10GB free storage** and **8GB RAM** - perfect for data analysis!

```bash
# Deploy frontend
railway login
railway link
railway up --service frontend

# Deploy backend separately
railway up --service backend
```

**Railway Configuration:**
- **Frontend**: Custom build command: `pnpm run build`, Start command: `npm run start`
- **Backend**: Start command: `npm run fastapi-prod`
- **Environment**: Set `BLOB_READ_WRITE_TOKEN` in Railway dashboard

### Vercel (Alternative)

```bash
# Deploy to Vercel
vercel --prod
```

**Environment Variables in Vercel:**
- `OPENAI_API_KEY`
- `BLOB_READ_WRITE_TOKEN`

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Next.js       â”‚    â”‚   FastAPI        â”‚    â”‚   OpenAI        â”‚
â”‚   Frontend      â”‚â—„â”€â”€â–ºâ”‚   Backend        â”‚â—„â”€â”€â–ºâ”‚   Responses API â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ File Upload   â”‚    â”‚ â€¢ Data Processingâ”‚    â”‚ â€¢ AI Analysis   â”‚
â”‚ â€¢ UI/UX         â”‚    â”‚ â€¢ API Routes     â”‚    â”‚ â€¢ Streaming     â”‚
â”‚ â€¢ Vercel Blob   â”‚    â”‚ â€¢ OpenAI Client  â”‚    â”‚ â€¢ Responses     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

**Frontend:**
- Next.js 13 (App Router)
- React 18
- TypeScript
- Tailwind CSS
- Vercel Blob (file storage)

**Backend:**
- FastAPI (Python)
- OpenAI Responses API
- Pydantic (data validation)
- Uvicorn (ASGI server)

**AI/ML:**
- OpenAI GPT-4
- Responses API (streaming)
- File processing capabilities

## ğŸ“š Documentation

- [File Upload Setup](./FILE_UPLOAD_SETUP.md) - Complete file upload guide
- [Quick Start](./QUICK_START.md) - Fast setup instructions
- [Feature Summary](./FEATURE_SUMMARY.md) - Technical overview

## ğŸ¯ Key Capabilities

- **Data Analysis**: Upload CSV/Excel files and get AI-powered insights
- **Document Analysis**: Analyze PDF reports and documents
- **Text Analysis**: Process text files and documents
- **Real-time Chat**: Streaming responses for better UX
- **File Management**: Visual file preview and removal
- **Error Handling**: Comprehensive validation and error messages

## ğŸ”§ Development

### Available Scripts

```bash
# Frontend only
pnpm run next-dev     # Next.js dev server
pnpm run build        # Production build
pnpm run start        # Production server

# Backend only
pnpm run fastapi-dev  # FastAPI dev server
pnpm run fastapi-prod # FastAPI production server

# Combined
pnpm run dev          # Both servers concurrently
pnpm run start:all    # Both servers in production mode
```

### Project Structure

```
â”œâ”€â”€ app/                 # Next.js app router
â”‚   â”œâ”€â”€ api/blob/       # File upload API routes
â”‚   â””â”€â”€ (chat)/         # Chat interface
â”œâ”€â”€ components/         # React components
â”‚   â”œâ”€â”€ multimodal-input.tsx  # File upload UI
â”‚   â””â”€â”€ markdown.tsx    # Math/LaTeX rendering
â”œâ”€â”€ api/                # FastAPI backend
â”‚   â”œâ”€â”€ index.py        # Main API routes
â”‚   â””â”€â”€ utils/          # Helper functions
â””â”€â”€ requirements.txt    # Python dependencies
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test thoroughly
5. Submit a pull request

## ğŸ“„ License

MIT License - see LICENSE file for details.

---

**Built with â¤ï¸ by AI Engineer Yasser Ali**
